# GitHub Actions Workflow for Automated Supabase Backups
#
# This workflow runs automated backups and uploads them to GitHub Releases
# or cloud storage (AWS S3, Google Cloud Storage, etc.)

name: Supabase Backup

on:
  # Run daily at 2 AM UTC
  schedule:
    - cron: '0 2 * * *'

  # Allow manual trigger
  workflow_dispatch:

  # Run on push to main (optional)
  # push:
  #   branches:
  #     - main

jobs:
  backup:
    runs-on: ubuntu-latest

    steps:
      - name: Checkout repository
        uses: actions/checkout@v4

      - name: Setup Node.js
        uses: actions/setup-node@v4
        with:
          node-version: '20'

      - name: Install PostgreSQL client
        run: |
          sudo apt-get update
          sudo apt-get install -y postgresql-client

      - name: Install dependencies
        run: npm install

      - name: Create backup
        env:
          SUPABASE_PROJECT_ID: ${{ secrets.SUPABASE_PROJECT_ID }}
          SUPABASE_URL: ${{ secrets.SUPABASE_URL }}
          SUPABASE_SERVICE_ROLE_KEY: ${{ secrets.SUPABASE_SERVICE_ROLE_KEY }}
          SUPABASE_DB_HOST: ${{ secrets.SUPABASE_DB_HOST }}
          SUPABASE_DB_PASSWORD: ${{ secrets.SUPABASE_DB_PASSWORD }}
          SUPABASE_DB_PORT: 5432
          SUPABASE_DB_NAME: postgres
          SUPABASE_DB_USER: postgres
          BACKUP_DIR: ./backups
        run: |
          npm run backup

      - name: Get backup directory
        id: backup_info
        run: |
          LATEST_BACKUP=$(ls -t backups | head -1)
          echo "backup_dir=backups/$LATEST_BACKUP" >> $GITHUB_OUTPUT
          echo "backup_name=$LATEST_BACKUP" >> $GITHUB_OUTPUT

      - name: Compress backup
        run: |
          cd backups
          tar -czf ${{ steps.backup_info.outputs.backup_name }}.tar.gz ${{ steps.backup_info.outputs.backup_name }}
          cd ..

      - name: Upload backup artifact
        uses: actions/upload-artifact@v4
        with:
          name: supabase-backup-${{ steps.backup_info.outputs.backup_name }}
          path: backups/${{ steps.backup_info.outputs.backup_name }}.tar.gz
          retention-days: 30

      # Optional: Upload to AWS S3
      # - name: Upload to S3
      #   env:
      #     AWS_ACCESS_KEY_ID: ${{ secrets.AWS_ACCESS_KEY_ID }}
      #     AWS_SECRET_ACCESS_KEY: ${{ secrets.AWS_SECRET_ACCESS_KEY }}
      #     AWS_REGION: us-east-1
      #   run: |
      #     aws s3 cp backups/${{ steps.backup_info.outputs.backup_name }}.tar.gz \
      #       s3://your-bucket-name/supabase-backups/

      # Optional: Upload to Google Cloud Storage
      # - name: Upload to GCS
      #   uses: google-github-actions/upload-cloud-storage@v2
      #   with:
      #     path: backups/${{ steps.backup_info.outputs.backup_name }}.tar.gz
      #     destination: your-bucket-name/supabase-backups/
      #     credentials: ${{ secrets.GCP_CREDENTIALS }}

      # Optional: Create GitHub Release
      # - name: Create Release
      #   uses: softprops/action-gh-release@v1
      #   with:
      #     tag_name: backup-${{ steps.backup_info.outputs.backup_name }}
      #     files: backups/${{ steps.backup_info.outputs.backup_name }}.tar.gz
      #   env:
      #     GITHUB_TOKEN: ${{ secrets.GITHUB_TOKEN }}

      - name: Cleanup old artifacts (keep last 7 days)
        uses: actions/github-script@v7
        with:
          script: |
            const days = 7;
            const ms = days * 24 * 60 * 60 * 1000;
            const now = Date.now();

            const { data: artifacts } = await github.rest.actions.listArtifactsForRepo({
              owner: context.repo.owner,
              repo: context.repo.repo,
            });

            for (const artifact of artifacts.artifacts) {
              if (artifact.name.startsWith('supabase-backup-')) {
                const createdAt = new Date(artifact.created_at).getTime();
                if (now - createdAt > ms) {
                  console.log(`Deleting artifact: ${artifact.name}`);
                  await github.rest.actions.deleteArtifact({
                    owner: context.repo.owner,
                    repo: context.repo.repo,
                    artifact_id: artifact.id,
                  });
                }
              }
            }
